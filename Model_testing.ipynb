{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Xc9Bf1bWHShPDm6cOqPmHO-kr6YPl9H0",
      "authorship_tag": "ABX9TyM3u5ZHGoE5ZuqP4+QJPILJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arko-14/HYDROPREDICT/blob/main/Model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYWxVdTm8QG",
        "outputId": "0f121bb0-0a6c-43c0-d4ff-aa9c381f1295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "# Loading the saved XGBoost model\n",
        "xgb_model = joblib.load('/content/drive/MyDrive/xgboost_model.joblib')\n",
        "print(\"XGBoost model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask[dataframe]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClgUf3eQoMjV",
        "outputId": "d3aeb464-c56a-4b6b-b5c8-c861b62188b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.2)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
            "  Downloading dask_expr-1.1.17-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.20.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n",
            "Downloading dask_expr-1.1.16-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dask-expr\n",
            "Successfully installed dask-expr-1.1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the test datasets\n",
        "try:\n",
        "    rainfall_test_data = pd.read_csv('/content/drive/MyDrive/dataset_train.csv', encoding='latin-1')\n",
        "    groundwater_test_data = pd.read_csv('/content/drive/MyDrive/groundwater_train2.csv', encoding='latin-1')\n",
        "\n",
        "    # Convert 'time' column to numeric, handling non-numeric values\n",
        "    print(\"Unique values in 'time' column before cleaning:\", rainfall_test_data['time'].unique())\n",
        "    rainfall_test_data['time'] = pd.to_numeric(rainfall_test_data['time'], errors='coerce')\n",
        "\n",
        "    # Check for NaN values after conversion and handle them\n",
        "    if rainfall_test_data['time'].isnull().any():\n",
        "        print(\"Warning: Found NaN values in 'time' column after conversion.\")\n",
        "        rainfall_test_data['time'].fillna(rainfall_test_data['time'].median(), inplace=True)\n",
        "\n",
        "    # Verify the conversion\n",
        "    print(\"Unique values in 'time' column after cleaning:\", rainfall_test_data['time'].unique())\n",
        "    rainfall_test_data['time'] = rainfall_test_data['time'].astype(float)\n",
        "\n",
        "    # Convert other columns to numeric if necessary\n",
        "    numeric_columns = ['time', 'precipitation(mm)', 'rain(mm)', 'temperature_80m (°C)', 'Year']\n",
        "    for col in numeric_columns:\n",
        "        rainfall_test_data[col] = pd.to_numeric(rainfall_test_data[col], errors='coerce')\n",
        "\n",
        "    # Handle any NaNs in the numeric columns\n",
        "    rainfall_test_data[numeric_columns] = rainfall_test_data[numeric_columns].fillna(rainfall_test_data[numeric_columns].median())\n",
        "\n",
        "    # Convert categorical columns using one-hot encoding\n",
        "    location_dummies = pd.get_dummies(rainfall_test_data['Location'], prefix='Location', drop_first=True)\n",
        "    month_dummies = pd.get_dummies(rainfall_test_data['Month'], prefix='Month', drop_first=True)\n",
        "\n",
        "    # Combine all features into the test set\n",
        "    X_test = pd.concat([rainfall_test_data[numeric_columns], location_dummies, month_dummies], axis=1)\n",
        "\n",
        "    # Define the target variable from groundwater data\n",
        "    y_test_groundwater = groundwater_test_data['Water Level'].astype(float)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred_groundwater = xgb_model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae_groundwater = mean_absolute_error(y_test_groundwater, y_pred_groundwater)\n",
        "    rmse_groundwater = np.sqrt(mean_squared_error(y_test_groundwater, y_pred_groundwater))\n",
        "    r2_groundwater = r2_score(y_test_groundwater, y_pred_groundwater)\n",
        "\n",
        "    print(\"Groundwater Level Predictions:\")\n",
        "    print(f\"Mean Absolute Error: {mae_groundwater:.4f}\")\n",
        "    print(f\"Root Mean Squared Error: {rmse_groundwater:.4f}\")\n",
        "    print(f\"R² Score: {r2_groundwater:.4f}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Could not find one of the data files. {e}\")\n",
        "except KeyError as e:\n",
        "    print(f\"Error: Missing required column. {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: An unexpected error occurred. {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF6YpGy8pIXT",
        "outputId": "51530785-d8ab-4411-b635-253ff523348d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'time' column before cleaning: ['2023-01-01T00:00' '2023-01-01T01:00' '2023-01-01T02:00' ...\n",
            " '2023-11-30T21:00' '2023-11-30T22:00' '2023-11-30T23:00']\n",
            "Warning: Found NaN values in 'time' column after conversion.\n",
            "Unique values in 'time' column after cleaning: [nan]\n",
            "Error: Missing required column. 'temperature_80m (°C)'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-15e25fb93859>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  rainfall_test_data['time'].fillna(rainfall_test_data['time'].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h78QzDmFrPb6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}